{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54561808",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c223b2e",
   "metadata": {},
   "source": [
    "This Notebook is focused on getting geo data and visualizing it.\n",
    "Output - df_geo dataframe in ./data/Data_frame_geoloc.pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e73228",
   "metadata": {},
   "source": [
    "# Geo parsing the data using longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computations, dataframes, additional libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Save data\n",
    "import pickle\n",
    "\n",
    "#GEO\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo columns from original dataset\n",
    "columns_geo = [\"lat\", \"id\", \"long\"]\n",
    "\n",
    "# Setup locator\n",
    "locator = Nominatim(user_agent= \"xz@gmail.com\" )\n",
    "\n",
    "#Load data\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "\n",
    "# Make test dataframe\n",
    "test_df = data[columns_geo].iloc[0:5]\n",
    "\n",
    "# Make sample dataframe for exploratory data analysis and finding features to fit the model.\n",
    "# Frac = the percentage of original dataframe (0.1 corresponds to 10%)\n",
    "sample_df = data[columns_geo].sample(frac = 0.03)\n",
    "\n",
    "\n",
    "# List of possible address fields\n",
    "raw_address_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of locator function \n",
    "location = locator.reverse([test_df[\"lat\"][0],test_df[\"long\"][0]])\n",
    "location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process of parsing data for our dataframe from OSM takes a long time due to limitation: 1 request per second.\n",
    "# For 21000 records it will take more than 6 hours. We need to create functions to save data during the process of saving as well as continue where we finished the process.\n",
    "# Function to check if the record already exist\n",
    "\n",
    "def nan_equal(a,b):\n",
    "        try:\n",
    "            np.testing.assert_equal(a,b)\n",
    "        except AssertionError:\n",
    "            return False\n",
    "        return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef52dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore function\n",
    "\n",
    "def geoloc_explore(record, raw_address_list):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    raw_address_list.append(location.raw)\n",
    "    time.sleep(1)             # 1 second delay due to OSM parsing limitations\n",
    "    if (i % 50 == 0):\n",
    "        print(f\"record {i}\")  # Check the progress\n",
    "    if (i % 150 == 0):\n",
    "        with open('./data/Geo_raw_file.pickle', 'wb') as f:   # Save the data\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Pickled\")\n",
    "    return raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fc70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "    raw_address_list = pickle.load(f)\n",
    "\n",
    "#Explore Sample dataset for unqiue features (uncomment to proceed)\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "        raw_address_list = geoloc_explore(sample_df.iloc[i], raw_address_list)\n",
    "\n",
    "# Final pickle of acquired data\n",
    "with open('./data/Geo_raw_file.pickle', 'wb') as f:\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Data is pickled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2021df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "    raw_address_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find possible features and create features frequency dictionary\n",
    "feature_list={}\n",
    "for address in raw_address_list:\n",
    "        address_features = list(address[\"address\"].keys())\n",
    "        for feature in address_features:\n",
    "            if feature not in feature_list:\n",
    "                feature_list[feature] = 1\n",
    "            else:\n",
    "                feature_list[feature] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd075fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore frequency dictionary\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626366ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dig deeper into usage of different fields, to find patterns that can be used later during data exploration\n",
    "# features_search must be changed to each value from feature_list, to find pattern of data\n",
    "features_search_list = []\n",
    "features_search = \"town\"\n",
    "for address in raw_address_list:\n",
    "    address_features = list(address[\"address\"].keys())\n",
    "    if features_search in address_features:\n",
    "        features_search_list.append(address)\n",
    "features_search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional check for \"type of cities involved\"\n",
    "# features_search_list = []\n",
    "# features_search = [\"city\", \"town\", \"village\"]\n",
    "# for address in raw_address_list:\n",
    "#     address_features = list(address[\"address\"].keys())\n",
    "#     if (features_search[0] not in address_features) and (features_search[1] not in address_features) and (features_search[2] not in address_features)  :\n",
    "#         features_search_list.append(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2f653a",
   "metadata": {},
   "source": [
    "We can see that there are 3 types of locations: towns, cities, villages. Some of them use different names for suburbs - suburbs, hamlet etc. \n",
    "All this information should be used to create correct dataframe later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61341b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to parse data\n",
    "def geoloc(record):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    print(lat, lon)\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    time.sleep(1)\n",
    "    return location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add88f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous analysis we created new features list for our dataframe\n",
    "New_features_list = [\"To_drop_place_ID\", \"To_drop_road\", \"Type_place\", \"city\", \"county\" , \"state\" , \"suburb\" ]\n",
    "\n",
    "# Create new geo dataframe\n",
    "df_geo = data[columns_geo].copy()\n",
    "\n",
    "# Add new features\n",
    "df_geo[New_features_list] = np.NAN\n",
    "\n",
    "# Check new DataFrame\n",
    "\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471026fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Data_frame_geoloc.pickle', 'rb') as df_geo_data:\n",
    "     df_geo = pickle.load(df_geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing algorithm based on previous data exploration\n",
    "\n",
    "for i in range(len(df_geo)):\n",
    "    if nan_equal(df_geo[\"state\"][i],\"Washington\"):  #Check if record already exist\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"Record {i} exist\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"New_record{i}\")\n",
    "        data = geoloc(df_geo.iloc[i])\n",
    "        df_geo[\"To_drop_place_ID\"][i]=data.get(\"place_id\")\n",
    "        df_geo[\"To_drop_road\"][i]=data.get(\"address\").get(\"road\")\n",
    "        df_geo[\"county\"][i]=data.get(\"address\").get(\"county\")\n",
    "        df_geo[\"state\"][i]=data.get(\"address\").get(\"state\")\n",
    "        if \"city\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"city\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"city\")\n",
    "        elif \"town\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"town\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"town\")\n",
    "        elif \"village\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"village\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"village\")\n",
    "        else:\n",
    "            df_geo[\"Type_place\"][i] = np.NAN\n",
    "            df_geo[\"city\"][i] = np.NAN \n",
    "        if \"suburb\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"suburb\"][i] = data.get(\"address\").get(\"suburb\")\n",
    "        elif \"hamlet\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"suburb\"][i] = data.get(\"address\").get(\"hamlet\")\n",
    "                                            \n",
    "        if (i % 100 == 0):\n",
    "            with open('./data/Data_frame_geoloc.pickle', 'wb') as df_geo_data:   #Save data, each 150 iterations\n",
    "                pickle.dump(df_geo, df_geo_data, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Pickled\", i) \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe after parsing\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bb315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with open('./data/Data_frame_geoloc.pickle', 'wb') as df_geo_data:   \n",
    "                pickle.dump(df_geo, df_geo_data, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Pickled\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c6da7d",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c893e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data is in file ./data/Data_frame_geoloc.pickle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
