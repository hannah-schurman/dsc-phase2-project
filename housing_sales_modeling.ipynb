{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2143fa",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a808f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c757c10",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d3157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bf3d23d",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e163e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d2ea247",
   "metadata": {},
   "source": [
    "## Geo parsing the data using longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import time\n",
    "import pickle\n",
    "import geoplotlib\n",
    "import pandas as pd\n",
    "from geoplotlib.utils import read_csv as read_csv2\n",
    "from shapely.geometry import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geo columns from original dataset\n",
    "columns_geo = [\"lat\", \"id\", \"long\"]\n",
    "\n",
    "# Setup locator\n",
    "locator = Nominatim(user_agent= \"xz@gmail.com\" )\n",
    "\n",
    "#Load data\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\")\n",
    "\n",
    "# Make test dataframe\n",
    "test_df = data[columns_geo].iloc[0:5]\n",
    "\n",
    "# Make sample dataframe for exploratory data analysis and finding features to fit the model.\n",
    "# Frac = the percentage of original dataframe (0.1 corresponds to 10%)\n",
    "sample_df = data[columns_geo].sample(frac = 0.03)\n",
    "\n",
    "\n",
    "# List of possible address fields\n",
    "raw_address_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of locator function \n",
    "location = locator.reverse([test_df[\"lat\"][0],test_df[\"long\"][0]])\n",
    "location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process of parsing data for our dataframe from OSM takes a long time due to limitation: 1 request per second.\n",
    "# For 21000 records it will take more than 6 hours. We need to create functions to save data during the process of saving as well as continue where we finished the process.\n",
    "# Function to check if the record already exist\n",
    "\n",
    "def nan_equal(a,b):\n",
    "        try:\n",
    "            np.testing.assert_equal(a,b)\n",
    "        except AssertionError:\n",
    "            return False\n",
    "        return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5132d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore function\n",
    "\n",
    "def geoloc_explore(record, raw_address_list):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    raw_address_list.append(location.raw)\n",
    "    time.sleep(1)             # 1 second delay due to OSM parsing limitations\n",
    "    if (i % 50 == 0):\n",
    "        print(f\"record {i}\")  # Check the progress\n",
    "    if (i % 150 == 0):\n",
    "        with open('./data/Geo_raw_file.pickle', 'wb') as f:   # Save the data\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "            print(\"Pickled\")\n",
    "    return raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d894e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "# with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "#     raw_address_list = pickle.load(f)\n",
    "\n",
    "# Explore Sample dataset for unqiue features (uncomment to proceed)\n",
    "\n",
    "for i in range(len(sample_df)):\n",
    "        raw_address_list = geoloc_explore(sample_df.iloc[i], raw_address_list)\n",
    "\n",
    "# Final pickle of acquired data\n",
    "with open('./data/Geo_raw_file.pickle', 'wb') as f:\n",
    "            pickle.dump(raw_address_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Data is pickled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40594aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d30df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional load of sample dataset from pickle\n",
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Geo_raw_file.pickle', 'rb') as f:\n",
    "    raw_address_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15ea79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find possible features and create features frequency dictionary\n",
    "feature_list={}\n",
    "for address in raw_address_list:\n",
    "        address_features = list(address[\"address\"].keys())\n",
    "        for feature in address_features:\n",
    "            if feature not in feature_list:\n",
    "                feature_list[feature] = 1\n",
    "            else:\n",
    "                feature_list[feature] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943918ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore frequency dictionary\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dig deeper into usage of different fields, to find patterns that can be used later during data exploration\n",
    "# features_search must be changed to each value from feature_list, to find pattern of data\n",
    "features_search_list = []\n",
    "features_search = \"town\"\n",
    "for address in raw_address_list:\n",
    "    address_features = list(address[\"address\"].keys())\n",
    "    if features_search in address_features:\n",
    "        features_search_list.append(address)\n",
    "features_search_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38087ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional check for \"type of cities involved\"\n",
    "# features_search_list = []\n",
    "# features_search = [\"city\", \"town\", \"village\"]\n",
    "# for address in raw_address_list:\n",
    "#     address_features = list(address[\"address\"].keys())\n",
    "#     if (features_search[0] not in address_features) and (features_search[1] not in address_features) and (features_search[2] not in address_features)  :\n",
    "#         features_search_list.append(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2dd815",
   "metadata": {},
   "source": [
    "We can see that there are 3 types of locations: towns, cities, villages. Some of them use different names for suburbs - suburbs, hamlet etc. \n",
    "All this information should be used to create correct dataframe later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to parse data\n",
    "def geoloc(record):\n",
    "    lat = record[\"lat\"]\n",
    "    lon = record[\"long\"]\n",
    "    print(lat, lon)\n",
    "    location = locator.reverse([lat,lon]) \n",
    "    time.sleep(1)\n",
    "    return location.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee36f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on previous analysis we created new features list for our dataframe\n",
    "New_features_list = [\"To_drop_place_ID\", \"To_drop_road\", \"Type_place\", \"city\", \"county\" , \"state\" , \"suburb\" ]\n",
    "\n",
    "# Create new geo dataframe\n",
    "df_geo = data[columns_geo].copy()\n",
    "\n",
    "# Add new features\n",
    "df_geo[New_features_list] = np.NAN\n",
    "\n",
    "# Check new DataFrame\n",
    "\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24da30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed data (uncomment to proceed)\n",
    "with open('./data/Data_frame_geoloc.pickle', 'rb') as df_geo_data:\n",
    "     df_geo = pickle.load(df_geo_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing algorithm based on previous data exploration\n",
    "\n",
    "for i in range(len(df_geo)):\n",
    "    if nan_equal(df_geo[\"state\"][i],\"Washington\"):  #Check if record already exist\n",
    "        if (i % 100 == 0):\n",
    "            print(f\"Record {i} exist\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"New_record{i}\")\n",
    "        data = geoloc(df_geo.iloc[i])\n",
    "        df_geo[\"To_drop_place_ID\"][i]=data.get(\"place_id\")\n",
    "        df_geo[\"To_drop_road\"][i]=data.get(\"address\").get(\"road\")\n",
    "        df_geo[\"county\"][i]=data.get(\"address\").get(\"county\")\n",
    "        df_geo[\"state\"][i]=data.get(\"address\").get(\"state\")\n",
    "        if \"city\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"city\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"city\")\n",
    "        elif \"town\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"town\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"town\")\n",
    "        elif \"village\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"Type_place\"][i] = \"village\"\n",
    "            df_geo[\"city\"][i] = data.get(\"address\").get(\"village\")\n",
    "        else:\n",
    "            df_geo[\"Type_place\"][i] = np.NAN\n",
    "            df_geo[\"city\"][i] = np.NAN \n",
    "        if \"suburb\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"suburb\"][i] = data.get(\"address\").get(\"suburb\")\n",
    "        elif \"hamlet\" in list(data.get(\"address\").keys()):\n",
    "            df_geo[\"suburb\"][i] = data.get(\"address\").get(\"hamlet\")\n",
    "                                            \n",
    "        if (i % 100 == 0):\n",
    "            with open('./data/Data_frame_geoloc.pickle', 'wb') as df_geo_data:   #Save data, each 150 iterations\n",
    "                pickle.dump(df_geo, df_geo_data, pickle.HIGHEST_PROTOCOL)\n",
    "                print(\"Pickled\", i) \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a8526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe after parsing\n",
    "print(f\"The number of records {len(df_geo)}\")\n",
    "display(df_geo.head())\n",
    "display(df_geo.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "with open('./data/Data_frame_geoloc.pickle', 'wb') as df_geo_data:   \n",
    "                pickle.dump(df_geo, df_geo_data, pickle.HIGHEST_PROTOCOL)\n",
    "print(\"Pickled\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed data (uncomment to proceed)\n",
    "# with open('./data/Data_frame_geoloc.pickle', 'rb') as df_geo_data:\n",
    "#     df_geo = pickle.load(df_geo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9978e1",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e256239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0766d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d70db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fills waterfront null values with NO because that is the most common option\n",
    "df['waterfront'] = df['waterfront'].fillna('NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "947b5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill na in views with none\n",
    "df['view'] = df['view'].fillna('NONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4514b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fills any rows with ? in sqft_basement with the sqft_living - sqft_above\n",
    "df['sqft_basement'] = np.where(df['sqft_basement'] == '?', df['sqft_living'] - df['sqft_above'], df['sqft_basement'])\n",
    "df['sqft_basement'] = df['sqft_basement'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b4246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maps waterfront to 0 or 1\n",
    "df['waterfront'] = df['waterfront'].map({'NO':0, 'YES':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75fab9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maps views with numerical values\n",
    "df['view'] = df['view'].map({'NONE':0, 'FAIR':1, 'AVERAGE':2, 'GOOD':3, 'EXCELLENT':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3817eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['yr_renovated'] = df['yr_renovated'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a440d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_coding (condition):\n",
    "    \"\"\"\n",
    "    This will take the condition from string format and transform it into a corresponding code in integer format\n",
    "    Poor = 1, Fair = 2, Average = 3, Good = 4, Very Good = 5\n",
    "    \"\"\"\n",
    "    if condition == 'Poor':\n",
    "        condition_code = 1\n",
    "    elif condition == 'Fair':\n",
    "        condition_code = 2\n",
    "    elif condition == 'Average':\n",
    "        condition_code = 3\n",
    "    elif condition == 'Good':\n",
    "        condition_code = 4\n",
    "    elif condition == 'Very Good':\n",
    "        condition_code = 5\n",
    "    return condition_code\n",
    "\n",
    "df['condition_code'] = df['condition'].map(condition_coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03d18ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_coding (grade):\n",
    "    \"\"\"\n",
    "    This takes the grade in string format, splits it into a list of characters\n",
    "    It then concatenates the first two characters from the list and strips the whitespace and turns the result into an integer\n",
    "    We are left with a one or two digit integer correspondinng to the grade of the property\n",
    "    \"\"\"\n",
    "    grade_list = list(grade)\n",
    "    grade_code = int((grade_list[0] + grade_list[1]).strip())\n",
    "    return grade_code\n",
    "\n",
    "df['grade_code'] = df['grade'].map(grade_coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "193a5e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = 2022 - df['yr_built']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53c9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renovated (year):\n",
    "    \"\"\"\n",
    "    This returns a True / False value on whether a property has been renovated or not\n",
    "    \"\"\"\n",
    "    if year == 0.0:\n",
    "        return False\n",
    "    elif year > 0.0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "df['renovated'] = df['yr_renovated'].map(renovated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f9c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a column of float values stating how old the renovations are on a property\n",
    "# If a property has not been renovated it will have a 0.0 value\n",
    "\n",
    "df['age_of_renovations'] = 2022 - df['yr_renovated']\n",
    "df.loc[df['age_of_renovations'] == 2022.00, 'age_of_renovations'] = 0.0\n",
    "df['age_of_renovations'] = df['age_of_renovations'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31b97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"data/df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7431ca4e",
   "metadata": {},
   "source": [
    "# Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f19f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "081fc45e",
   "metadata": {},
   "source": [
    "# Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105cadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b6bc39",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e89fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
